{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from osgeo import gdal, ogr\n",
    "from netCDF4 import Dataset\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "import os, os.path\n",
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "%matplotlib inline\n",
    "directory = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>nv</th>\n",
       "      <th>time</th>\n",
       "      <th>lat_bnds</th>\n",
       "      <th>lon_bnds</th>\n",
       "      <th>analysed_sst</th>\n",
       "      <th>analysis_error</th>\n",
       "      <th>mask</th>\n",
       "      <th>sea_ice_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-89.875</td>\n",
       "      <td>-179.875</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>-90.00</td>\n",
       "      <td>-180.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-89.875</td>\n",
       "      <td>-179.875</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>-89.75</td>\n",
       "      <td>-179.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-89.875</td>\n",
       "      <td>-179.625</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>-90.00</td>\n",
       "      <td>-179.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-89.875</td>\n",
       "      <td>-179.625</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>-89.75</td>\n",
       "      <td>-179.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-89.875</td>\n",
       "      <td>-179.375</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>-90.00</td>\n",
       "      <td>-179.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lat      lon  nv       time  lat_bnds  lon_bnds  analysed_sst  \\\n",
       "0 -89.875 -179.875   0 2017-10-31    -90.00   -180.00           NaN   \n",
       "1 -89.875 -179.875   1 2017-10-31    -89.75   -179.75           NaN   \n",
       "2 -89.875 -179.625   0 2017-10-31    -90.00   -179.75           NaN   \n",
       "3 -89.875 -179.625   1 2017-10-31    -89.75   -179.50           NaN   \n",
       "4 -89.875 -179.375   0 2017-10-31    -90.00   -179.50           NaN   \n",
       "\n",
       "   analysis_error  mask  sea_ice_fraction  \n",
       "0             NaN   2.0               NaN  \n",
       "1             NaN   2.0               NaN  \n",
       "2             NaN   2.0               NaN  \n",
       "3             NaN   2.0               NaN  \n",
       "4             NaN   2.0               NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www1.ncdc.noaa.gov/pub/data/cmb/ersst/v5/netcdf/\n",
    "sst = xr.open_dataset(directory+\"/temp/global/ersst/ersst.v5.201805.nc\").to_dataframe()\n",
    "sst.reset_index(inplace=True)\n",
    "\n",
    "#better data than above\n",
    "#gathered two data points for each month (Oct - May?) to get a general feel for the temp in this growth/harvest period\n",
    "filelist = os.listdir(directory+\"/temp/global/oisst\") \n",
    "df_list = [xr.open_dataset('../data/temp/global/oisst/'+file).to_dataframe() for file in filelist]\n",
    "oisst = pd.concat(df_list)\n",
    "oisst.reset_index(inplace=True)\n",
    "oisst['analysed_sst'] -= 273.15\n",
    "oisst.head()\n",
    "print(oisst.shape)\n",
    "print(min(oisst.lat), max(oisst.lat),min(oisst.lon),max(oisst.lon))\n",
    "quicklook = oisst[(oisst.lat >=35) & (oisst.lat <=36) & (oisst.lon >= -124) & (oisst.lon <=-122)]\n",
    "quicklook.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mean, max, and min temps for the data\n",
    "mean_temps = oisst.groupby(['lat_bnds','lon_bnds']).mean()\n",
    "max_temps = oisst.groupby(['lat_bnds','lon_bnds']).max()\n",
    "min_temps = oisst.groupby(['lat_bnds','lon_bnds']).min()\n",
    "mean_temps.reset_index(inplace=True)\n",
    "max_temps.reset_index(inplace=True)\n",
    "min_temps.reset_index(inplace=True)\n",
    "max_temps['max_temp'] = max_temps.analysed_sst\n",
    "min_temps['min_temp'] = min_temps.analysed_sst\n",
    "#remove data cols which are useless/I don't understand\n",
    "mean_temps.drop(['mask','sea_ice_fraction','analysis_error','nv'], axis=1, inplace=True)\n",
    "max_temps.drop(['time','mask','sea_ice_fraction','analysed_sst','lat','lon','analysis_error','nv'],\\\n",
    "               axis=1, inplace=True)\n",
    "min_temps.drop(['time','mask','sea_ice_fraction','analysed_sst','lat','lon','analysis_error','nv'],\\\n",
    "               axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate into one big df\n",
    "sst_overview = mean_temps.merge(max_temps, on=[\"lat_bnds\",\"lon_bnds\"], how='inner')\\\n",
    "                         .merge(min_temps, on=[\"lat_bnds\",\"lon_bnds\"], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get values for a given point. We may want to do the kirging option instead of this.\n",
    "lat = 35.863\n",
    "lon = -133.72\n",
    "vertices = (sst_overview.iloc[np.sqrt((sst_overview.lon_bnds-lon)**2+(sst_overview.lat_bnds-lat)**2).argsort()[:3]])\n",
    "vertices.reset_index(drop=True, inplace = True)\n",
    "print(vertices)\n",
    "#set these to find out which row contains the closest pair along the lat/long axes.\n",
    "lat_pair = None\n",
    "lon_pair = None\n",
    "if vertices.iloc[0].lat_bnds == vertices.iloc[1].lat_bnds:\n",
    "    lat_diff = abs(vertices.iloc[0].lat_bnds - vertices.iloc[2].lat_bnds)\n",
    "    lon_diff = abs(vertices.iloc[0].lon_bnds - vertices.iloc[1].lon_bnds)\n",
    "    lat_pair = 1\n",
    "    long_pair = 2\n",
    "else:\n",
    "    lat_diff = abs(vertices.iloc[0].lat_bnds - vertices.iloc[1].lat_bnds)\n",
    "    lon_diff = abs(vertices.iloc[0].lon_bnds - vertices.iloc[2].lon_bnds)\n",
    "    lat_pair = 2\n",
    "    lon_pair = 1\n",
    "print(\"lat_diff: {}, lon_diff: {}\".format(lat_diff, lon_diff))\n",
    "\n",
    "point_lat_diff = round(abs(vertices.iloc[0].lat_bnds - lat),2)\n",
    "point_lon_diff = round(abs(vertices.iloc[0].lon_bnds - lon),2)\n",
    "print(\"point_lat_diff: {}, point_lon_diff: {}\".format(point_lat_diff, point_lon_diff))\n",
    "point_lat_pct = point_lat_diff/lat_diff\n",
    "point_lon_pct = point_lon_diff/lon_diff\n",
    "print(\"point_lat_pct: {}, point_lon_pct: {}\".format(point_lat_pct, point_lon_pct))\n",
    "\n",
    "lat_temp_diff = vertices.iloc[lat_pair] - vertices.iloc[0]\n",
    "lon_temp_diff = vertices.iloc[lon_pair] - vertices.iloc[0]\n",
    "\n",
    "point_lat_temp = lat_temp_diff*point_lat_pct\n",
    "point_lon_temp = lon_temp_diff*point_lon_pct\n",
    "#print(\"poin_lat_temp: {}, point_lon_temp: {}\".format(point_lat_temp, point_lon_temp))\n",
    "\n",
    "#take into account negative temperature changes\n",
    "length_fraction = (point_lat_temp + point_lon_temp)/(abs(point_lat_temp)+ abs(point_lon_temp))\n",
    "point_temp = vertices.iloc[0]+length_fraction*(np.sqrt(point_lat_temp**2+point_lon_temp**2))\n",
    "print(point_temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Bathymetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bath = xr.open_dataset(\"../../data/bathymetry/coastal_relief_maps/crm_vol7.nc\").to_dataframe()\n",
    "bath.reset_index(inplace=True)\n",
    "print(\"max x: {}, min x: {}, max y :{} min y: {}\".format(max(bath.x), min(bath.x), max(bath.y), min(bath.y)))\n",
    "#region = bath[(bath.x >=-121.8) & (bath.x<=-121.5) & (bath.y >=34.5) & (bath.y<=34.9)]\n",
    "#region.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = bath[(bath.x >=-124.11) & (bath.x<=-124.10) & (bath.y >=40.0) & (bath.y<=40.3)]\n",
    "region.head()\n",
    "bath.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read critical species habitats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in black abalone data\n",
    "#create a dictionary for reference of which species may intersect with a site\n",
    "crit_species_dfs = {}\n",
    "black_abalone = gpd.read_file(\"../../data/critical/california/black_abalone/BlackAbFinalCH10272011.shp\")\n",
    "crit_species_dfs['black_abalone'] = black_abalone\n",
    "# doesn't return any new info afaict\n",
    "#babalshz = gpd.read_file(\"../../data/critical/california/black_abalone/BlackAbFinalCH10272011.shz\")\n",
    "#babalshz.head()\n",
    "#site_intersections = sum(black_abalone.intersects(Polygon([[-123, 39],[-123,32],[-120,39],[-120,32]])))\n",
    "\n",
    "leatherback = gpd.read_file(\"../../data/critical/california/leatherback/Final_LeatherbackCH.shp\")\n",
    "crit_species_dfs['leatherback'] = leatherback\n",
    "\n",
    "stellar_sealions = gpd.read_file(\"../../data/critical/california/stellar_sealions/StellerSLionCritHab_OR_CA.shp\")\n",
    "crit_species_dfs['stellar_sealions'] = stellar_sealions\n",
    "\n",
    "#green sturgeon had many shp files, most of which were irrelevant for our immediate purposes.\n",
    "#I concatenated to relevant ones\n",
    "#not relevant\n",
    "#GreenSturgeonCHBypassAreas.shp (interior california)\n",
    "#GreenSturgeonCHDepartmentofDefense.shp (not in ca)\n",
    "#GreenSturgeonCHHeadOfTide.shp (interior)\n",
    "#GreenSturgeonCHMarshAreas.shp (interior)\n",
    "#GreenSturgeonCHStreams.shp (streams)\n",
    "#GreenSturgeonCHTribalExclusions.shp\n",
    "\n",
    "#relevant\n",
    "#GreenSturgeonCHEstuaries.shp\n",
    "#GreenSturgeonCHMarineCoastalZones.shp\n",
    "\n",
    "green_sturgeon = gpd.read_file\\\n",
    "(\"../../data/critical/california/green_sturgeon/GreenSturgeonFinalCH/GreenSturgeonCHEstuaries.shp\")\n",
    "green_sturgeon = green_sturgeon.append(gpd.read_file\\\n",
    "(\"../../data/critical/california/green_sturgeon/GreenSturgeonFinalCH/GreenSturgeonCHMarineCoastalZones.shp\"))\n",
    "crit_species_dfs['green_sturgeon'] = green_sturgeon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
